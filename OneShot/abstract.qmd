---
title: "Learned one-shot imaging"
author:
  - name: Mathias Louboutin
    affiliations:
      name: Georgia Institute of Technology
  - name: Rafael Orozco
    affiliations:
      name: Georgia Institute of Technology
  - name: Felix J. Herrmann
    affiliations:
      name: Georgia Institute of Technology
description: | 
  Learned super-shot/sim-source pair for one-shot imaging.
bibliography: abstract.bib
abstract: |
  Learn simultenaous sources and super shot simulteanously
---

::: hidden
$$
    \newcommand{\pluseq}{\mathrel{+}=}
$$
:::

# Image 2023 abstract

## OBJECTIVES AND SCOPE (100 words)

Seismic imaging's main limiting factor is the scale of the involved dataset and the number of independent wave-equations solves required to migrate thousands of shots. To tackle this dimensionality curse, we introduce a learned framework that extends the conventional computationally reductive linear source superposition (e.g. via random simultaneous-source encoding) to a nonlinear learned source superposition and its corresponding learned super-shot. With this method, we can obtain an image of the subsurface at the cost of a one-shot migration by learning the most informative superposition of shots.

## METHODS, PROCEDURES, PROCESS (250 words)

Simultaneous-source imaging takes advantage of the linearity of the wave equation by adding different encoded (e.g., via random weights or time shifts) shot records together reducing the number of wave-equation solves and therefore the cost of imaging. Because of the linearity, the same linear transformation can be applied to both the sources and shot records to maintain source-shot record consistency. Here, we introduce a nonlinear superposition, and to compensate for the inability to apply the corresponding transform to the source, we simultaneously learn the nonlinear source and nonlinear data encodings with two neural networks. The first network takes the shot records as input and outputs learned supershots. The second network takes the nonlinearly encoded shot data as input and produces encoded simultaneous source. The network is trained in two ways. First, we train a supervised network minimizing the difference between imaged nonlinear supershots, migrated with nonlinearly simultaneous sources the true reflectivity, which requires access to the true model. Since in practice the true subsurface image is unknown, we also train a second unsupervised network minimizing the difference between the observed shot data and the migrated-demigrated supershots. In both cases, the networks learn how to encode source-shot data pairs that maximize subsurface information---i.e., the networks jointly learn how to encode and insonify to extract maximal information on the image.

## RESULTS, OBSERVATIONS, CONCLUSIONS (250 words)
<!-- I made it to here -->

Results for the learned supervised and unsurpervised one-shot imaging are included in Figures 1 and 2, respectively. For reference, the original shot data are included on the left, followed by the learned one-shot data and learned source. Corresponding images are plotten on the right. From the plots, the following observations can be made. First, one can see from Figure 1 that the learned one-shot reverse-time migration (RTM) result constitutes a major improvement compared to the image obtained with convensional random source encoding (juxtapose images in the first column on the left). Second, the one-shot imaging result is also better than convention sequential source RTM since it is closer to the true reflectitivity plotted at the top of the right column. This improvement in the image's frequency content can be explained by the fact that in the supervided case the network are trained to broadband reflectivities. Third, for the unsupervised case we find that similar observations hold except that the improvement in image quality is slightly less. Because the encouded source distribution is learned, our method does not need information on the source signatures. 
<!--In Figure 1, we show results obtained with supervised training and an Figure 2 with unsupervised training. We juxtapose the learned nonlinear supershot and randomized simultenous source next to the true observed data and compare the obtained one-shot subsurface image with standard multi-source RTM and conventional random simultenous sources imaging. We see that the image is not only less noisy that the standard simultenous source image but also a better representation of the subsurface than the conventional RTM. This demonstrate that we can obtain a good image of the earth at the cost of a single source migration while avoiding the artifacts associated with conventional simultenous source imaging.-->

## SIGNIFICANCE/NOVELTY (100 words)

We introduced a first instance of a new one-shot nonlinear simultenaous source imaging paradigm. After incurring initial training costs, the method is capable of producing high-fidelity images at the cost of migrating single shot records, which entails a drastic reduction in migration costs. Training of the networks is also relatively cheap because it also involves single-source operations. 

<!--Because only linear transforms can be applied to the source and data using the linearity of the wave-equation, we introduced a neural network capable of creating a pair of simultenous source and super-shot that is most informative for migration. This learned on-shot imaging framework allows to drastically reduce the cost of seismic imaging while requiring limited training resources since only single-shot are migrated.-->

# Supplementary material

## Introduction

## Methodology

We now introduce the formulation of aour learned simultenous source-data pair for seismic imaging. We derive two training problem where the first onbe rely on the knowledge of the true perturbation, while the second one solely rely on the observed data. Fundamentally, we are introducing a formulation that learns the most informative single super-shot and correspoinding source given either a subsurface refelctivity model or the surface recorded data.

### Summary networks and probabilistic symmetry

[@deans2002maximally] -Summary statistics reduce the size of incoming datasets while maintainting the same posterior distribution p(x\|y) = p(x\|summary) [@radev2020bayesflow] -Summary networks learn to reduce the size of incoming datasets and maximize informativeness of the summarized data due to joint learning of summary network and posterior learning network. -hand waves an argument that jointly trained networks will maximize the mutual information between h(y) and x [@muller2021learning] -Goes in to further detail and rigoursly proves that jointly trained networks will maximize the mutual information between h(y) and x [@bloem2020probabilistic] suggests to use learned layers that are invariant under a certain transformation. This transformation is described by the probabilistic assumption on your data.

Example paragraph: This work takes inspiration from the concept of a summary network [@radev2020bayesflow] these are networks that compress observables $d_{obs}$ while maximining information useful for inference of un-observables $x$. To guide the architectural design of a summary network [@bloem2020probabilistic] suggests to use learned layers that respect the probabalistic symmetry of the data. Practically, this is accomplished by making the layers be invariant under a certain transformation. For the case active source seismic imaging, i.i.d sampling entails the assumption that the order of sources does not matter. This assumption is implicit in the sum structure of RTM/gradient calculations. Therefore it is invariant with respect to permutation transformation. Our approach is most similar to this case, since we use a UNet with many input channels that output a single channel. In our testing, having a separate network for each dataset did not perform better thatn simply inputing each dataset along a channel.

### Supervised

THe simplest formulation aims to learn the super-shot and simultenaous source that best inform the model perturbation, given the surfac recorded data. Mathematically, it means that we are trying to fit the true mode lperturbation with two networks that learn a single super-shot and simultenous source for the Jacobian from the indicudual field recorded shot records. Mathematically, the learning can be written as: 
$$
\min_{\theta, \phi} \ \mathbb{E}\left[ J(\mathcal{H}_{\phi}(\mathcal{G}_{\theta}(d_{\text{obs}}))^\top \mathcal{G}_{\theta}(d_{\text{obs}}) - \delta m \right] 
$$ {#eq-supervised}

where $\mathcal{H}_{\phi}, \mathcal{G}_{\theta}$ are the two networks mapping the individual shot records into a single super-shot (the learned simultenous-source is learned at the receiver locations), $J$ is the conventionnal adjoint Born imaging operator, $d_{\text{obs}}$ is the observed data and $\delta m$ is the model perturbation. We note that to compute an update on the two networks simultenaously, the gradient of the Jacobian with respect to its source is necessary. This derivative is however trivial to obtain with [JUDI.jl](https://github.com/slimgroup/JUDI.jl) thanks to its high-level linear algebra abstraction and integration with automatic differentiation framework in Julia.

### Unsupervised

$$
\min_{\theta, \phi} \ \mathbb{E}\left[ \tilde{J}_{\text{rtm}} J(\mathcal{H}_{\phi}(\mathcal{G}_{\theta}(d_{\text{obs}}))^\top \mathcal{G}_{\theta}(d_{\text{obs}}) - \tilde{d}_{\text{obs}} \right ]
$$ {#eq-unsupervised}

Where $\tilde{d}_{\text{obs}} = \sum_{i=1}^{n_src} w_i d_{\text{obs},i}$ is a random super shot with $w_i := \mathcal{N}(0, 1)$ and $\tilde{J}$ is the corresponding simultenous source born modeling operator. While this formulation ivolves an additional demigration (and therfore and additional migration to compute hte gradient), we do not require any knowledge of the true model perturbation but only the data. We could therefore in theory use this formulation for a wide range of datasets at once to generalize to any survey.

## Synthetic case studies

We illustrate our method on a realstic 2D imaging problem. We created a dataset of 2000 2D slices by extracting slices out of the 3D overthrust model. We then split this dataset into 1600 slices for trainng and 400 slices for testing. For each 2D slice, we generate 21 shot records. One of the main advantage of our one-shot imaging method is that we only require a single migration-demigration per iteration. Therefore, we can perform 21 epochs before arriving to a computationnal cost equivalent to the plain standard RTM imaging of each slice. Since we only perform 15 epochs, our method is overall cheapper than computing the RTM on every single shot if we include the cost of training.

We trained the networks, both in the supervised and unsupervised case, for 15 epochs with a learning rate of $.0004$ using the Adam optimizer.

::: {#fig-sup layout-ncol="2"}
![Data](figures/sup-data.png){width="50%"}

![RTMs](figures/sup-im.png){width="50%"}

Learned super-shot and simultenous sources on a testing slice. We show a shot record and the moirated image with a random supershot and with sequential shots for reference.
:::

::: {#fig-unsup layout-ncol="2"}
![Data](figures/unsup-data.png){width="50%"}

![RTMs](figures/unsup-im.png){width="50%"}

Learned super-shot and simultenous sources on a testing slice. We show a shot record and the moirated image with a random supershot and with sequential shots for reference.
:::

### Code availability

Results presented here can be reproduced with the software and examples in [OneShotImaging.jl](https://github.com/mloubout/OneShotImaging).

## Discussion and conclusions

We introduced data-domain learning method that provides high accuracy imagies of the subsurface through one-shot imaging. We trained a network that learns the simultenous source and super-shot that most inform the subsurface from the field recorded data. We showed that we obtain high accuracy images of the subsurface that contain broader frequency range than standard imaging and does not require prior knowledge of the source. Additionnally, the overall computationnal cost of training does not exceed the traditionnal cost of imaging.

## Acknowledgement

This research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.

### References

::: {#refs}
:::