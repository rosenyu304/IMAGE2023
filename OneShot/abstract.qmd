---
title: "Learned one-shot imaging"
author:
  - name: Mathias Louboutin
    affiliations:
      name: Georgia Institute of Technology
  - name: Rafael Orozco
    affiliations:
      name: Georgia Institute of Technology
  - name: Ali Siahkoohi
    affiliations:
      name: Rice University
  - name: Felix J. Herrmann
    affiliations:
      name: Georgia Institute of Technology
description: | 
  Learned supershot/sim-source pair for one-shot imaging.
bibliography: abstract.bib
abstract: |
  Learn sources and super shot simultaneously
---

::: hidden
$$
    \newcommand{\pluseq}{\mathrel{+}=}
$$
:::

# Image 2023 abstract

## OBJECTIVES AND SCOPE (600 characters)

Seismic imaging's main limiting factor is the scale of the involved dataset and the number of independent wave-equation solves required to migrate thousands of shots. To tackle this dimensionality curse, we introduce a learned framework that extends the conventional computationally reductive linear source superposition (e.g., via random simultaneous-source encoding) to a nonlinear learned source superposition and its corresponding learned supershot. With this method, we can image the subsurface at the cost of a one-shot migration by learning the most informative superposition of shots.

## METHODS, PROCEDURES, PROCESS (1500 characters)

Simultaneous-source imaging takes advantage of the linearity of the wave equation by combining encoded (e.g., via random weights or time shifts) shot records together, reducing the number of wave-equation solves and therefore the cost of imaging. Because of the linearity, the same linear transformation can be applied to the sources to maintain source-shot consistency. To further reduce imaging costs, we propose using nonlinear encodings, and to compensate for the inability to apply the corresponding transform to the source, we simultaneously learn the nonlinear source and nonlinear data encodings with two deep networks. The first network takes shot records as input and outputs a learned supershot. The second network produces the associated nonlinearly encoded simultaneous source given this supershot. Lastly, we migrate the supershot using the nonlinear simultaneous source to obtain the one-shot seismic image. To jointly train these networks, we propose supervised and unsupervised formulations. In the supervised method, networks aim to minimize the difference between the predicted image and the ground-truth seismic image. Our unsupervised approach eliminates the need for true models, making the technique applicable in practice, by minimizing the difference between the observed data and the migrated-demigrated supershots. In both cases, the networks learn how to encode and insonify source-shot data pairs to extract maximal information on the image using a single super shot.

## RESULTS, OBSERVATIONS, CONCLUSIONS (1500 characters)
<!-- I made it to here -->

We apply the proposed one-shot imaging approach to a previously unseen shot data. The cost of one-shot imaging is approximately the same as a single shot migration as network evaluation costs are negligible. Results for the learned supervised and unsupervised one-shot imaging are presented in Figures 1 and 2, respectively. For reference, the original shot data are included on the left, followed by the learned supershot data and learned source. Corresponding images are plotted on the right. Figure 1 shows that the learned one-shot reverse-time migration (RTM) result constitutes a major improvement compared to the image obtained with conventional random source encoding (juxtapose images in the first column on the left). The one-shot imaging result is also better than convention sequential source RTM since it is closer to the true reflectivity plotted at the top of the right column. This improvement in the image's frequency content can be explained by the fact that in the supervised learning formulation the the networks are jointly trained to produce broadband seismic images. Similarly, we find that similar observations are true for the unsupervised case, except that the improvement in image quality is slightly less pronounced. Besides being computationally inexpensive and providing high-fidelity images, since the source encoding is learned from data, our method requires no knowledge of the source signatures.
<!--In Figure 1, we show results obtained with supervised training and an Figure 2 with unsupervised training. We juxtapose the learned nonlinear supershot and randomized simultenous source next to the true observed data and compare the obtained one-shot subsurface image with standard multi-source RTM and conventional random simultenous sources imaging. We see that the image is not only less noisy that the standard simultenous source image but also a better representation of the subsurface than the conventional RTM. This demonstrate that we can obtain a good image of the earth at the cost of a single source migration while avoiding the artifacts associated with conventional simultenous source imaging.-->

## SIGNIFICANCE/NOVELTY (600 characters)

We introduced the first instance of learned nonlinear simultaneous-source encoding, enabling one-shot simultaneous-source seismic imaging. After incurring initial training costs, the method is capable of producing high-fidelity images at the cost of migrating a single shot record, which entails a drastic reduction in migration costs. We introduced supervised and unsupervised training formulations, the latter of which does not require knowledge of true subsurface images and only relies on a dataset of shot records from several seismic surveys, making it applicable in realistic settings.

<!-- We introduced a first instance of a new one-shot nonlinear simultaneous source imaging paradigm. After incurring initial training costs, the method is capable of producing high-fidelity images at the cost of migrating single shot records, which entails a drastic reduction in migration costs. Training of the networks is also relatively cheap because it also involves single-source operations.  -->

<!--Because only linear transforms can be applied to the source and data using the linearity of the wave-equation, we introduced a neural network capable of creating a pair of simultenous source and supershot that is most informative for migration. This learned on-shot imaging framework allows to drastically reduce the cost of seismic imaging while requiring limited training resources since only single-shot are migrated.-->

# Supplementary material

## Introduction


[@deans2002maximally] -Summary statistics reduce the size of incoming datasets while maintainting the same posterior distribution p(x\|y) = p(x\|summary) [@radev2020bayesflow] -Summary networks learn to reduce the size of incoming datasets and maximize informativeness of the summarized data due to joint learning of summary network and posterior learning network. -hand waves an argument that jointly trained networks will maximize the mutual information between h(y) and x [@muller2021learning] -Goes in to further detail and rigoursly proves that jointly trained networks will maximize the mutual information between h(y) and x [@bloem2020probabilistic] suggests to use learned layers that are invariant under a certain transformation. This transformation is described by the probabilistic assumption on your data.



## Methodology

Here we present our formulation for a learned simultaneous source-data pair for seismic imaging. We propose two training formulations, one that relies on knowledge of the true perturbation (supervised), and the other that solely relies on the observed data (unsupervised). Fundamentally, we are introducing a formulation that learns a single supershot and corresponding source that maximally informs seismic imaging. Next section describes the design of the deep networks that enable this goal.

<!-- We now introduce the formulation of our learned simultaneous source-data pair for seismic imaging. We derive two training formulations where the first one relies on the knowledge of the true perturbation (supervised), while the second one solely rely on the observed data (unsupervised). Fundamentally, we are introducing a formulation that learns the most informative single supershot and corresponding source given either a subsurface reflectivity model or the surface recorded data. -->

### Summary networks

To handle the high-dimensionality of seismic data and, we use summary networks [@radev2020bayesflow] that are designed to exploit the intrinsic low-dimensional structure [ref needed to curvelet etc] of seismic data. These deep networks compress the observed seismic data $\mathbf{d}$ while maximally preserving the information useful for inferring the unknown seismic image $\delta \mathbf{m}$. A major aspect of the architectural design of a summary networks are exploiting the invariances in data, e.g., invariance to permutation [@bloem2020probabilistic]. This is achieved by choosing neural architectures with functional forms that explicitly respect the intrinsic invariances in data. For example in the case of seismic imaging, the order of shot records has no effect on the final seismic image. To make this invariance explicit in the design of our network, we sum the shot records and feed it to a deep convolutional neural network.


<!-- Example paragraph: This work takes inspiration from the concept of a summary network [@radev2020bayesflow] these are networks that compress observables $d_{obs}$ while maximining information useful for inference of un-observables $x$. To guide the architectural design of a summary network [@bloem2020probabilistic] suggests to use learned layers that respect the symmetry of the data. Practically, this is accomplished by making the layers be invariant under a certain transformation. For the case active source seismic imaging, i.i.d sampling entails the assumption that the order of sources does not matter. This assumption is implicit in the sum structure of RTM/gradient calculations. Therefore it is invariant with respect to permutation transformation. Our approach is most similar to this case, since we use a UNet with many input channels that output a single channel. In our testing, having a separate network for each dataset did not perform better thatn simply inputing each dataset along a channel. -->

### Supervised

The simplest formulation aims to learn the supershot and simultaneous source that best inform the model perturbation, given the surface recorded data. Mathematically, it means that we are trying to fit the true model  perturbation with two networks that learn a single supershot and simultaneous source for the Jacobian from the individual field recorded shot records. Mathematically, the learning can be written as: 
$$
\min_{\boldsymbol{\theta}, \boldsymbol{\phi}} \ \mathbb{E}_{(\mathbf{d}, \delta \mathbf{m}) \sim p(\mathbf{d}, \delta \mathbf{m})} \left[ \frac{1}{2} \Big\| \mathbf{J}\big(\mathcal{H}_{\phi} \circ \mathcal{G}_{\theta} \left(\mathbf{d}\right)\big)^\top \mathcal{G}_{\theta}(\mathbf{d}) - \delta \mathbf{m} \Big\|_2^2 \right],
$$ {#eq-supervised}

where $\mathcal{G}_{\theta}$ is the summary network that maps shot records to a learned, nonlinearly mixed supershot at the receiver locations, $\mathcal{H}_{\phi}$ is the neural network responsible for estimating the associated nonlinearly encoded simultaneous source, and $\circ$ is the composition operator. The objective function matches the predicted seismic image, obtained by migrating the supershot $\mathcal{G}_{\theta}(\mathbf{d})$ via the adjoint Born imaging operator,  $\mathbf{J}$, to the ground truth seismic image $\delta \mathbf{m}$. We note that to evaluate the gradient of the objective function with jointly respect to $\boldsymbol{\theta}$ and $\boldsymbol{\phi}$, the gradient of the Jacobian with respect to its input (nonlinearly encoded source) is required. This derivative is, however, trivial to obtain with [JUDI.jl](https://github.com/slimgroup/JUDI.jl) thanks to its high-level linear algebra abstraction and integration with automatic differentiation framework in Julia.

### Unsupervised

To extend our approach to more realistic settings, we propose an unsupervised learning one-shot imaging approach that only requires a dataset of seismic shot records from several surveys. We formulate the problem as a minimization of the following objective function:

$$
\min_{\boldsymbol{\theta}, \boldsymbol{\phi}} \ \mathbb{E}_{\mathbf{d} \sim p(\mathbf{d})} \left[ \frac{1}{2} \Big\|  \tilde{\mathbf{J}} \mathbf{J}\big(\mathcal{H}_{\phi} \circ \mathcal{G}_{\theta}(\mathbf{d})\big)^\top \mathcal{G}_{\theta}(\mathbf{d}) - \tilde{\mathbf{d}} \Big\|_2^2  \right ],
$$ {#eq-unsupervised}

where $\tilde{\mathbf{d}} = \sum_{i=1}^{n_{\text{src}}} w_i \mathbf{d}_{i}$ is a random super shot with $w_i := \mathcal{N}(0, 1)$ and $\tilde{\mathbf{J}}$ is the corresponding simultaneous source born modeling operator. While this formulation ivolves an additional demigration (and therfore and additional migration to compute hte gradient), we do not require any knowledge of the true model perturbation but only the data. We could therefore in theory use this formulation for a wide range of datasets at once to generalize to any survey.

## Synthetic case studies

We illustrate our method on a realstic 2D imaging problem. We created a dataset of 2000 2D slices by extracting slices out of the 3D overthrust model. We then split this dataset into 1600 slices for trainng and 400 slices for testing. For each 2D slice, we generate 21 shot records. One of the main advantage of our one-shot imaging method is that we only require a single migration-demigration per iteration. Therefore, we can perform 21 epochs before arriving to a computationnal cost equivalent to the plain standard RTM imaging of each slice. Since we only perform 15 epochs, our method is overall cheapper than computing the RTM on every single shot if we include the cost of training.

We trained the networks, both in the supervised and unsupervised case, for 15 epochs with a learning rate of $.0004$ using the Adam optimizer.

::: {#fig-sup layout-ncol="2"}
![Data](figures/sup-data.png){width="50%"}

![RTMs](figures/sup-im.png){width="50%"}

Learned supershot and simultenous sources on a testing slice. We show a shot record and the moirated image with a random supershot and with sequential shots for reference.
:::

::: {#fig-unsup layout-ncol="2"}
![Data](figures/unsup-data.png){width="50%"}

![RTMs](figures/unsup-im.png){width="50%"}

Learned supershot and simultenous sources on a testing slice. We show a shot record and the moirated image with a random supershot and with sequential shots for reference.
:::

### Code availability

Results presented here can be reproduced with the software and examples in [OneShotImaging.jl](https://github.com/mloubout/OneShotImaging).

## Discussion and conclusions

We introduced data-domain learning method that provides high accuracy imagies of the subsurface through one-shot imaging. We trained a network that learns the simultenous source and supershot that most inform the subsurface from the field recorded data. We showed that we obtain high accuracy images of the subsurface that contain broader frequency range than standard imaging and does not require prior knowledge of the source. Additionnally, the overall computationnal cost of training does not exceed the traditionnal cost of imaging.

## Acknowledgement

This research was carried out with the support of Georgia Research Alliance and partners of the ML4Seismic Center.

### References

::: {#refs}
:::