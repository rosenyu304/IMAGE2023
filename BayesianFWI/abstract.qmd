---
title: "Amortized Bayesian Full Waveform Inversion and Experimental Design with Normalizing Flows"
author:
  - name: Rafael Orozco
    affiliations:
      name: Georgia Institute of Technology
  - name: Mathias Louboutin
    affiliations:
      name: Georgia Institute of Technology
  - name: Felix J. Herrmann
    affiliations:
      name: Georgia Institute of Technology
description: | 
  empty
bibliography: abstract.bib
abstract: |
  empty
---

# Image 2023 abstract

## OBJECTIVES AND SCOPE (100 words)
Probabistic approaches to Full Waveform Inversion (FWI), such as Bayesian ones, traditionally require expensive computations. To reduce this computational burden at test time, we propose to amortize the computational cost with an offline training phase. After training, our method aims to efficiently generate probabilistic FWI solutions with uncertainty information. This objective is achieved by exploiting the ability of deep generative neural networks (i.e. Normalizing Flows) to learn distributions, in this case, the Bayesian posterior. The uncertainty information in the posterior is used during offline training to find the optimal experimental design with respect to receiver placement. 

## METHODS, PROCEDURES, PROCESS (250 words)
Normalizing flows (NFs) are generative networks that can learn to sample from conditional distributions, i.e. our desired Bayesian posterior p(x\|y) where x are earth models and y is seismic data. To train NFs, we require training pairs of these earth models and seismic data. We use pairs from the open source dataset OPENFWI. The earth models are 64x64 size and the seismic data is simulated with 5 source experiments with 15Hz frequency and 15dB noise.

The NFs training objective (illustrated in Figure 1) has been shown to be equivalent to maximizing the information gain used in Bayesian experimental design. Thus, we propose to jointly optimize a mask M that occludes receivers of the seismic data (M.\*y) during NF training. Our optimization jointly optimizes for NF parameters and optimal mask M values in a single objective (Equation 1 in Figure 1).

We use the CurveFault_B dataset from OPENFWI which contains 55k pairs. We use a 90/5/5 split. 

## RESULTS, OBSERVATIONS, CONCLUSIONS (250 words)
After training, our method generates posterior samples at the cost of one neural network pass (10ms on our GPU). Seen in Figure 2, the posterior samples are realistic earth models that could plausibly match the seismic data. The small variations between the models are due to the FWI problem being ill-posed and because of noise in the indirect observations at the subsurface. To study these variations we take the sample variance as our uncertainty quantification. We note that the uncertainty is concentrated on vertical structures and deeper ones. 

To make a single high-quality solution, we take the mean of the posterior samples. The posterior mean shows high-quality metrics that surpass previous benchmarks on the OPENFWI dataset while our method produces Bayesian uncertainty and the benchmark methods do not. 

The optimal experimental design found by our method (filled-in circles in Figure 2 represent optimal receiver locations) matches prior expectations that the most important information is contained in the short offsets. This result was independently discovered by the Bayesian optimization routine.

## SIGNIFICANCE/NOVELTY (100 words)
To our knowledge, this is the first demonstration of conditional normalizing flows on amortized FWI with uncertainty quantification. We also showed a practical application of the uncertainty towards experimental design. While the open source dataset has small models, NFs are memory efficient due to their intrinsic invertibility so are set to scale to realistic sized problems.


